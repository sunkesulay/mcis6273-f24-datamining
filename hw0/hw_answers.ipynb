{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "327a0aea-af20-4c9e-a65b-8060bdcc4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task : Unzip the file\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Unzip the file and storing into the 'data/' directory\n",
    "os.makedirs('./data/', exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile('hw0_dataset_1M.csv.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "151a1d1d-9efa-4a41-b6f5-61bb62b871f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0            1                2                        3           4   \\\n",
      "0  NaN          key  doi-asserted-by                      DOI  first-page   \n",
      "1  0.0  e_1_2_7_2_1        publisher         10.1038/35041545         NaN   \n",
      "2  1.0  e_1_2_7_3_1        publisher  10.1126/science.1155121         NaN   \n",
      "3  2.0  e_1_2_7_4_1        publisher    10.1007/s003820050007         NaN   \n",
      "4  3.0  e_1_2_7_5_1        publisher     10.1029/2000GL012471         NaN   \n",
      "\n",
      "             5       6     7       8              9   ...  20  21  22  23  24  \\\n",
      "0  volume-title  author  year  volume  journal-title  ... NaN NaN NaN NaN NaN   \n",
      "1           NaN     NaN   NaN     NaN            NaN  ... NaN NaN NaN NaN NaN   \n",
      "2           NaN     NaN   NaN     NaN            NaN  ... NaN NaN NaN NaN NaN   \n",
      "3           NaN     NaN   NaN     NaN            NaN  ... NaN NaN NaN NaN NaN   \n",
      "4           NaN     NaN   NaN     NaN            NaN  ... NaN NaN NaN NaN NaN   \n",
      "\n",
      "   25  26  27  28  29  \n",
      "0 NaN NaN NaN NaN NaN  \n",
      "1 NaN NaN NaN NaN NaN  \n",
      "2 NaN NaN NaN NaN NaN  \n",
      "3 NaN NaN NaN NaN NaN  \n",
      "4 NaN NaN NaN NaN NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "The above output is before cleaning the extra columns \n",
      "42114          key doi-asserted-by               first-page  DOI  \\\n",
      "1      e_1_2_7_2_1       publisher         10.1038/35041545  NaN   \n",
      "2      e_1_2_7_3_1       publisher  10.1126/science.1155121  NaN   \n",
      "3      e_1_2_7_4_1       publisher    10.1007/s003820050007  NaN   \n",
      "4      e_1_2_7_5_1       publisher     10.1029/2000GL012471  NaN   \n",
      "5      e_1_2_7_6_1       publisher     10.1029/2007GL029678  NaN   \n",
      "\n",
      "42114 article-title volume author year journal-title unstructured issue  \\\n",
      "1               NaN    NaN    NaN  NaN           NaN          NaN   NaN   \n",
      "2               NaN    NaN    NaN  NaN           NaN          NaN   NaN   \n",
      "3               NaN    NaN    NaN  NaN           NaN          NaN   NaN   \n",
      "4               NaN    NaN    NaN  NaN           NaN          NaN   NaN   \n",
      "5               NaN    NaN    NaN  NaN           NaN          NaN   NaN   \n",
      "\n",
      "42114 series-title volume-title edition ISSN issn-type isbn-type ISBN  \n",
      "1              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "2              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "3              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "4              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "5              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "#Task: Loading the dataset into a data frame (df)\n",
    "import pandas as pd\n",
    "\n",
    "#load the CSV into a DataFrame\n",
    "df = pd.read_csv( \"./data/hw0_dataset_1M.csv\", names = [i for i in range(0,30)], on_bad_lines=\"skip\", low_memory=False)\n",
    "# Displaying the first few rows to know the structure\n",
    "print(df.head())\n",
    "print(\"The above output is before cleaning the extra columns \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Ensuring that the second column (index 1) is treated as a string\n",
    "df[1] = df[1].astype(str)\n",
    "# Identifying rows where the second column (column with index 1) contains the word 'key'\n",
    "header_rows = df[df[1].str.contains('key', case=False, na=False)]\n",
    "\n",
    "# Finding the longest Header row\n",
    "header_row = header_rows.loc[header_rows.notna().sum(axis=1).idxmax()]\n",
    "\n",
    "# Setting this row as the new header\n",
    "df.columns = header_row\n",
    "\n",
    "# Remove extraneous rows (including the rows used as header)\n",
    "df = df.drop(header_rows.index)\n",
    "\n",
    "# Dropping columns where the header value is NaN\n",
    "df_cleaned = df.loc[:, df.columns.notna()]\n",
    "\n",
    "# Dropping any rows with all NaN values which is optional\n",
    "df_cleaned = df_cleaned.dropna(how='all')\n",
    "\n",
    "# Displaying the first few rows of the cleaned DataFrame\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "4270d088-a64d-4aa0-adfc-87b63c25999a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data has been saved to 'data/cleaned_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Saving the cleaned data into 'data/cleaned_data_selected_columns.csv'\n",
    "df_cleaned.to_csv('data/cleaned_data.csv', index=False)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Cleaned data has been saved to 'data/cleaned_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "ed1dbcf4-06cf-4503-979b-00e60ebe5f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'data/data_cleaned_normalized.csv' and 'data/data_cleaned_normalized.json'.\n"
     ]
    }
   ],
   "source": [
    "# Task: Extract,transform and export JSON data\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Restrict the data to the required 3 columns: 'DOI', 'journal-title', and 'doi-asserted-by'\n",
    "df_transformed = df_cleaned[['DOI', 'journal-title', 'doi-asserted-by']].copy()\n",
    "\n",
    "# Normalize the DOI column (convert to lowercase) using .loc[] \n",
    "df_transformed['DOI'] = df_transformed['DOI'].str.lower()\n",
    "\n",
    "\n",
    "df_transformed['journal-title'] = df_transformed['journal-title'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()) if pd.notnull(x) else x)\n",
    "\n",
    "# Removing all punctuation from 'journal-title'\n",
    "df_transformed['journal-title'] = df_transformed['journal-title'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x) if pd.notnull(x) else x)\n",
    "\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save the transformed data into a CSV file\n",
    "csv_filename = 'data/data_cleaned_normalized.csv'\n",
    "df_transformed.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Save the transformed data into a JSON file\n",
    "json_filename = 'data/data_cleaned_normalized.json'\n",
    "df_transformed.to_json(json_filename, orient='records', lines=True)\n",
    "\n",
    "# Confirmation message\n",
    "print(f\"Data has been saved to '{csv_filename}' and '{json_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "e8e60cd7-d3df-403a-be1b-239ff74eb323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before selection: Index(['key', 'doi-asserted-by', 'first-page', 'DOI', 'article-title',\n",
      "       'volume', 'author', 'year', 'journal-title', 'unstructured', 'issue',\n",
      "       'series-title', 'volume-title', 'edition', 'ISSN', 'issn-type',\n",
      "       'isbn-type', 'ISBN'],\n",
      "      dtype='object', name=42114)\n",
      "Columns after selection: Index(['DOI', 'journal-title'], dtype='object', name=42114)\n",
      "Filtered data saved to 'data/data_filtered.csv' and 'data/data_filtered.json'.\n"
     ]
    }
   ],
   "source": [
    "#Task: Filter, transform and export CSV data.\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to filter data for rows with DOI and journal-title, ensure unique DOIs, and export only those columns\n",
    "def filter_and_export_data(df, csv_output_path, json_output_path):\n",
    "    # Filter rows where both DOI and journal-title are not empty\n",
    "    df_filtered = df.dropna(subset=['DOI', 'journal-title'])\n",
    "\n",
    "    # Remove duplicate DOIs (keeping only the first occurrence)\n",
    "    df_filtered_unique = df_filtered.drop_duplicates(subset='DOI')\n",
    "\n",
    "    # Debugging step: Print the current columns to verify selection\n",
    "    print(\"Columns before selection:\", df_filtered_unique.columns)\n",
    "\n",
    "    # Select only DOI and journal-title columns\n",
    "    df_filtered_final = df_filtered_unique[['DOI', 'journal-title']].copy()  # Select only these two columns\n",
    "\n",
    "    # Debugging step: Verify that the resulting DataFrame only contains the two columns\n",
    "    print(\"Columns after selection:\", df_filtered_final.columns)\n",
    "\n",
    "    # Ensure the 'data' directory exists\n",
    "    os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n",
    "\n",
    "    # Export to CSV\n",
    "    df_filtered_final.to_csv(csv_output_path, index=False)\n",
    "\n",
    "    # Export to JSON\n",
    "    df_filtered_final.to_json(json_output_path, orient='records', lines=True)\n",
    "\n",
    "    print(f\"Filtered data saved to '{csv_output_path}' and '{json_output_path}'.\")\n",
    "\n",
    "# Example usage assuming df_cleaned is available\n",
    "csv_output_path = 'data/data_filtered.csv'\n",
    "json_output_path = 'data/data_filtered.json'\n",
    "\n",
    "# Call the function to filter, transform, and export data\n",
    "filter_and_export_data(df_cleaned, csv_output_path, json_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "96563b26-f915-4afb-85ad-2fcf61586b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count  count\n",
      "0  publisher  21037\n",
      "1   crossref  14421\n",
      "2          1   1096\n",
      "3     2006.0    828\n",
      "4     2007.0    791\n",
      "42114                                   key doi-asserted-by  \\\n",
      "22        c2cs35095e-(cit3)/*[position()=1]        crossref   \n",
      "59       c2cs35095e-(cit44)/*[position()=1]        crossref   \n",
      "86       c2cs35095e-(cit74)/*[position()=1]        crossref   \n",
      "89       c2cs35095e-(cit77)/*[position()=1]        crossref   \n",
      "108      c2cs35095e-(cit96)/*[position()=1]        crossref   \n",
      "...                                     ...             ...   \n",
      "992036    10.1016/j.jastp.2009.03.026_bib43        crossref   \n",
      "992053                       erlac36f6bib16       publisher   \n",
      "992222   10.1016/S1352-2310(00)00275-2_BIB1        crossref   \n",
      "992226   10.1016/S1352-2310(00)00275-2_BIB5        crossref   \n",
      "992249  10.1016/S1352-2310(00)00275-2_BIB29        crossref   \n",
      "\n",
      "42114                                        first-page     DOI  \\\n",
      "22                              10.1126/science.1210026     183   \n",
      "59                              10.1126/science.1174760     716   \n",
      "86                              10.1126/science.1207374     794   \n",
      "89                              10.1126/science.1174461     187   \n",
      "108                             10.1126/science.1181568     672   \n",
      "...                                                 ...     ...   \n",
      "992036                     10.1016/0032-0633(83)90030-2      53   \n",
      "992053                     10.1126/science.266.5186.753     753   \n",
      "992222  10.1175/1520-0469(1977)034<0531:AMOTEO>2.0.CO;2   531.0   \n",
      "992226                     10.1126/science.278.5339.827   827.0   \n",
      "992249  10.1175/1520-0469(1976)033<2399:ODNSOT>2.0.CO;2  2399.0   \n",
      "\n",
      "42114                                       article-title    volume  \\\n",
      "22                                                    NaN  Shindell   \n",
      "59                                                    NaN  Shindell   \n",
      "86                                                    NaN  Mahowald   \n",
      "89                                                    NaN     Myhre   \n",
      "108                                                   NaN    Arneth   \n",
      "...                                                   ...       ...   \n",
      "992036  F-region neutral winds and temperatures at equ...        31   \n",
      "992053  Fragmentation and flow regulation of river sys...     266.0   \n",
      "992222  A model of the effect of aerosols on urban cli...        34   \n",
      "992226  The impact of aerosols on solar UV radiation a...       278   \n",
      "992249  One-dimensional numerical simulation of the ef...        33   \n",
      "\n",
      "42114       author    year                   journal-title unstructured issue  \\\n",
      "22          2012.0   335.0                         Science          NaN   NaN   \n",
      "59          2009.0   326.0                         Science          NaN   NaN   \n",
      "86          2011.0   334.0                         Science          NaN   NaN   \n",
      "89          2009.0   325.0                         Science          NaN   NaN   \n",
      "108         2009.0   326.0                         Science          NaN   NaN   \n",
      "...            ...     ...                             ...          ...   ...   \n",
      "992036      Sipler  1983.0     Planetary and Space Science          NaN   NaN   \n",
      "992053    Dynesius    1994                         Science          NaN   NaN   \n",
      "992222    Ackerman  1977.0  Journal of Atmospheric Science          NaN   NaN   \n",
      "992226   Dickerson  1997.0                         Science          NaN   NaN   \n",
      "992249  Zdunkowski  1976.0  Journal of Atmospheric Science          NaN   NaN   \n",
      "\n",
      "42114  series-title volume-title edition ISSN issn-type isbn-type ISBN  \n",
      "22              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "59              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "86              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "89              NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "108             NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "...             ...          ...     ...  ...       ...       ...  ...  \n",
      "992036          NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "992053          NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "992222          NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "992226          NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "992249          NaN          NaN     NaN  NaN       NaN       NaN  NaN  \n",
      "\n",
      "[5793 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "#Task: Write functions to get journal information.\n",
    "\n",
    "def n_most_frequent_doi(df, n):\n",
    "    # Get the frequency count of DOIs and sort them in descending order\n",
    "    doi_counts = df['DOI'].value_counts().head(n)\n",
    "    \n",
    "    # Return the DataFrame containing the n most frequent DOIs\n",
    "    return doi_counts.reset_index().rename(columns={'index': 'DOI', 'DOI': 'count'})\n",
    "\n",
    "def journal_lookup(df, s):\n",
    "    # Filter rows where the journal-title contains the substring s (case insensitive)\n",
    "    filtered_df = df[df['journal-title'].str.contains(s, case=False, na=False)]\n",
    "    \n",
    "    # Return the filtered DataFrame\n",
    "    return filtered_df\n",
    "\n",
    "# Assuming df_cleaned is your cleaned DataFrame\n",
    "\n",
    "# Get the 5 most frequent DOIs\n",
    "most_frequent_dois = n_most_frequent_doi(df_cleaned, 5)\n",
    "print(most_frequent_dois)\n",
    "\n",
    "# Lookup journals with 'Science' in the title\n",
    "journal_results = journal_lookup(df_cleaned, 'Science')\n",
    "print(journal_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd125d5-b8a7-4d63-be60-bdbd77933b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
